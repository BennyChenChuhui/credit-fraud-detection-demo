{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "based on: https://www.kaggle.com/code/zwhjorth/dnn-svm-and-dt-for-fraud-detection\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Env var\n",
    "MLFLOW_ROUTE = os.getenv(\"MLFLOW_ROUTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch data\n",
    "Data = pd.read_csv('./data/card_transdata.csv')\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data\n",
    "Data['Log_home'] = np.log10(Data['distance_from_home'])\n",
    "Data['Log_trans'] = np.log10(Data['distance_from_last_transaction'])\n",
    "Data['Log_ratio'] = np.log10(Data['ratio_to_median_purchase_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Data.drop(columns = ['fraud', 'Log_home','Log_trans','Log_ratio'])\n",
    "y = Data['fraud']\n",
    "\n",
    "# Splitting the data into test and train\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, stratify = y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.2, stratify = y_train)\n",
    "\n",
    "# It is important to only fit the scaler to the training data, otherwise you are leaking\n",
    "# information about the global distribution of variables (which is influenced by the test set)\n",
    "# into the train set.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Getting class weights\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "class_weights = {i : class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim = len(X.columns)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_ROUTE)\n",
    "mlflow.set_experiment(\"DNN-credit-fraud\")\n",
    "mlflow.tensorflow.autolog(registered_model_name=\"DNN-credit-fraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    epochs = 2\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, \\\n",
    "                        validation_data=(scaler.transform(X_val),y_val), \\\n",
    "                        verbose = True, class_weight = class_weights)\n",
    "    # mlflow.log_param(\"epochs\", epochs)\n",
    "    # mlflow.log_metric(\"val_loss\", history.history['val_loss'][0])\n",
    "    # mlflow.log_metric(\"val_accuracy\", history.history['val_accuracy'][0])\n",
    "    # mlflow.tensorflow.log_model(model)\n",
    "    y_pred_temp = model.predict(scaler.transform(X_test)) \n",
    "\n",
    "    threshold = 0.995\n",
    "\n",
    "    y_pred = np.where(y_pred_temp > threshold, 1,0)\n",
    "    c_matrix = confusion_matrix(y_test,y_pred)\n",
    "    ax = sns.heatmap(c_matrix, annot=True, cbar=False, cmap='Blues')\n",
    "    ax.set_xlabel(\"Prediction\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    t_n, f_p, f_n, t_p = c_matrix.ravel()\n",
    "    mlflow.log_metric(\"tn\", t_n)\n",
    "    mlflow.log_metric(\"fp\", f_p)\n",
    "    mlflow.log_metric(\"fn\", f_n)\n",
    "    mlflow.log_metric(\"tp\", t_p)\n",
    "\n",
    "    # mlflow.tensorflow.log_model(history)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('ai-on-openshift')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1634c0bc43905e7916bfdb805d9fa90ddc101c0f948f75bff344e1199ec8d02f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
